{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+00, tolerance: 2.215e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.636e+01, tolerance: 2.240e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+01, tolerance: 2.204e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.267e+00, tolerance: 2.200e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+01, tolerance: 2.254e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Metric      Value\n",
      "0   Mean Squared Error (MSE)   0.145557\n",
      "1  Mean Absolute Error (MAE)   0.258164\n",
      "2                  R-squared   0.976454\n",
      "3   Model Accuracy (R² in %)  97.645441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        # Read Excel file into a DataFrame\n",
    "        data = pd.read_excel(file_path)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Drop unnecessary columns if they exist\n",
    "    cols_to_drop = ['Unnamed: 0', 'sample_title', 'organism', 'BioSample', \n",
    "                    'BioProject', 'AssemblyAccession', 'BioSampleAccn', \n",
    "                    'SubmitterOrganization', 'geo_loc_name']\n",
    "    data = data.drop(columns=[col for col in cols_to_drop if col in data.columns], errors='ignore')\n",
    "    \n",
    "    # Convert date columns to numerical (UNIX timestamp)\n",
    "    if 'collection_date' in data.columns:\n",
    "        # Specify date format if known\n",
    "        data['collection_date'] = pd.to_datetime(data['collection_date'], format='%Y-%m-%d', errors='coerce')\n",
    "        data['collection_date'] = data['collection_date'].astype('int64') // 10**9  # Convert to seconds\n",
    "    \n",
    "    # Drop rows where target 'BRD_Total' is missing\n",
    "    data = data.dropna(subset=['BRD_Total'])\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X = data.drop(columns=['BRD_Total'])\n",
    "    y = data['BRD_Total']\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    num_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Fill missing numerical values with mean\n",
    "    num_imputer = SimpleImputer(strategy='mean')\n",
    "    imputed_data = num_imputer.fit_transform(X[num_cols])\n",
    "    \n",
    "    # Ensure imputed data matches the original number of columns\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=num_cols, index=X.index[:len(imputed_data)])\n",
    "    \n",
    "    # Replace numerical columns in X with imputed values\n",
    "    for col in num_cols:\n",
    "        X.loc[:, col] = imputed_df[col]\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col in cat_cols:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "    \n",
    "    # Ensure all data is numerical before splitting\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_lasso_model(X_train, y_train):\n",
    "    try:\n",
    "        # Define pipeline with Lasso model\n",
    "        pipeline = Pipeline([\n",
    "            ('lasso', Lasso())\n",
    "        ])\n",
    "        \n",
    "        # Define hyperparameter tuning space\n",
    "        param_grid = {\n",
    "            'lasso__alpha': np.logspace(-4, 0, 5)\n",
    "        }\n",
    "        \n",
    "        # Perform grid search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    except Exception as e:\n",
    "        print(f\"Error training model: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Calculate \"accuracy\" as the percentage of variance explained by the model\n",
    "        r2_percentage = r2 * 100\n",
    "        \n",
    "        # Create a DataFrame to display the metrics\n",
    "        metrics = {\n",
    "            'Metric': ['Mean Squared Error (MSE)', 'Mean Absolute Error (MAE)', 'R-squared', 'Model Accuracy (R² in %)'],\n",
    "            'Value': [mse, mae, r2, r2_percentage]\n",
    "        }\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "        \n",
    "        return metrics_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model: {e}\")\n",
    "        return None\n",
    "\n",
    "def main(file_path):\n",
    "    # Load the data\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    if data is not None:\n",
    "        # Preprocess the data\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(data)\n",
    "        \n",
    "        # Train the Lasso regression model\n",
    "        lasso = train_lasso_model(X_train, y_train)\n",
    "        \n",
    "        if lasso is not None:\n",
    "            # Evaluate the model\n",
    "            metrics_df = evaluate_model(lasso, X_test, y_test)\n",
    "            \n",
    "            if metrics_df is not None:\n",
    "                # Print the evaluation results in tabular format\n",
    "                print(metrics_df)\n",
    "\n",
    "# Example usage (replace with actual path to your Excel file)\n",
    "file_path = 'fulldataset.xlsx'  # Replace with the actual file path\n",
    "main(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
