{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values detected! Replacing them.\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1488 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 900         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007556426 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | -0.000185   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.41e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.84e+03    |\n",
      "|    ep_rew_mean          | -2.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009401819 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | -0.013      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.47e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.84e+03      |\n",
      "|    ep_rew_mean          | -2.68e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 658           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079900003 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.649        |\n",
      "|    explained_variance   | 0.00739       |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 2.76e+03      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000454     |\n",
      "|    value_loss           | 5.99e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.84e+03    |\n",
      "|    ep_rew_mean          | -2.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008294844 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | -0.000374   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.45e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 4.83e+03    |\n",
      "-----------------------------------------\n",
      "Model Accuracy: 6.34%\n",
      "\n",
      "Model Training Results Table:\n",
      "   Learning Rate  Training Rate  Model Accuracy (%)  Correct Predictions  \\\n",
      "0         0.0001          10000            6.336701                  370   \n",
      "\n",
      "   Total Predictions  \n",
      "0               5839  \n",
      "No intervention needed.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install Dependencies\n",
    "# Install required libraries\n",
    "# pip install gym stable-baselines3 pandas numpy\n",
    "\n",
    "# Step 2: Import Libraries\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Step 3: Create the Custom Environment for Bovine Respiratory Disease Prediction\n",
    "class BovineRespiratoryDiseaseEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(BovineRespiratoryDiseaseEnv, self).__init__()\n",
    "        \n",
    "        # Load the dataset containing cattle health metrics\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Action space: Decide on health intervention (e.g., increase observation, administer medication)\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = No intervention, 1 = Intervention\n",
    "        \n",
    "        # Observation space: Use the cattle health data features (e.g., temperature, heart rate)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(data.shape[1] - 1,), dtype=np.float32)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset the environment to the initial state\n",
    "        self.current_step = 0\n",
    "        return self.data.iloc[self.current_step, :-1].values\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Get current observation\n",
    "        observation = self.data.iloc[self.current_step, :-1].values\n",
    "        \n",
    "        # Calculate reward: higher rewards for correctly predicting intervention (preventing BRD)\n",
    "        reward = 0\n",
    "        if action == 1 and self.data.iloc[self.current_step]['BRD_Total'] == 1:  # Disease present, intervention made\n",
    "            reward = 10  # Positive reward for correct intervention\n",
    "        elif action == 0 and self.data.iloc[self.current_step]['BRD_Total'] == 0:  # No disease, no intervention\n",
    "            reward = 5  # Positive reward for no action when no disease present\n",
    "        else:\n",
    "            reward = -5  # Negative reward for incorrect action\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data)\n",
    "        \n",
    "        return observation, reward, done, {}\n",
    "\n",
    "# Step 4: Load Your Dataset from a CSV File\n",
    "# Example: 'cattle_health_data.csv' should be replaced with your actual file path\n",
    "file_path = r\"fulldataset.xlsx\"\n",
    "# Load the dataset\n",
    "data = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# Step 5: Prepare Data for Training\n",
    "# Fill NaN values in the 'BRD_Total' column with 0\n",
    "data['BRD_Total'] = data['BRD_Total'].fillna(0).astype(int)\n",
    "\n",
    "# Normalize the data (optional but helpful for RL)\n",
    "# Make sure to normalize the feature columns (except for the target column 'BRD_Total')\n",
    "data_normalized = data.copy()\n",
    "\n",
    "# Select only numeric columns for normalization\n",
    "numeric_columns = data_normalized.select_dtypes(include=[np.number]).columns\n",
    "data_normalized[numeric_columns] = data_normalized[numeric_columns] / (data_normalized[numeric_columns].max() + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Ensure the environment receives only numeric data\n",
    "data_normalized = data_normalized[numeric_columns]\n",
    "\n",
    "# Check for NaN values in the data\n",
    "if data_normalized.isnull().sum().any():\n",
    "    print(\"NaN values detected! Replacing them.\")\n",
    "    data_normalized = data_normalized.fillna(0)\n",
    "\n",
    "# Step 6: Train the RL Model\n",
    "# Create the custom environment\n",
    "env = BovineRespiratoryDiseaseEnv(data_normalized)\n",
    "\n",
    "# Initialize the PPO model with a lower learning rate to avoid NaNs\n",
    "learning_rate = 0.0001\n",
    "training_rate = 10000\n",
    "model = PPO('MlpPolicy', env, learning_rate=learning_rate, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=training_rate)\n",
    "\n",
    "# Step 7: Evaluate the Model and Calculate Accuracy\n",
    "# Initialize variables for tracking correct and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Test the trained agent\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "# Evaluate over the entire dataset\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    \n",
    "    # Compare predicted action to actual disease state to determine correctness\n",
    "    if (action == 1 and env.data.iloc[env.current_step - 1]['BRD_Total'] == 1) or \\\n",
    "       (action == 0 and env.data.iloc[env.current_step - 1]['BRD_Total'] == 0):\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "    \n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Step 8: Make a Table of Results\n",
    "# Create a table with the model's learning rate, training rate, and accuracy\n",
    "results = {\n",
    "    \"Learning Rate\": [learning_rate],\n",
    "    \"Training Rate\": [training_rate],\n",
    "    \"Model Accuracy (%)\": [accuracy],\n",
    "    \"Correct Predictions\": [correct_predictions],\n",
    "    \"Total Predictions\": [total_predictions]\n",
    "}\n",
    "\n",
    "results_table = pd.DataFrame(results)\n",
    "print(\"\\nModel Training Results Table:\")\n",
    "print(results_table)\n",
    "\n",
    "# Step 9: Making Predictions with the Trained Model\n",
    "# Example: Make a prediction for the next cattle observation\n",
    "test_observation = np.array([0.6, 0.7, 0.8, 0.5])  # Replace with actual data\n",
    "\n",
    "# Ensure the test observation has the correct shape (e.g., 32 features)\n",
    "# If your data has fewer than 32 features, you might need to pad or extend this observation\n",
    "# Here we manually extend it to match the expected size.\n",
    "test_observation = np.pad(test_observation, (0, 32 - len(test_observation)), 'constant')\n",
    "\n",
    "# Reshape the observation to add a batch dimension (1, 32)\n",
    "test_observation = test_observation.reshape(1, -1)\n",
    "\n",
    "# Get the prediction\n",
    "action, _states = model.predict(test_observation)\n",
    "\n",
    "# Output action\n",
    "if action == 1:\n",
    "    print(\"Intervene: Cattle at risk of BRD.\")\n",
    "else:\n",
    "    print(\"No intervention needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values detected! Replacing them.\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | -220     |\n",
      "| time/              |          |\n",
      "|    fps             | 1474     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 365         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1031        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012246516 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | -0.000528   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 983         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 808         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017019656 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | -0.0118     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 1.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008231869 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 541         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 915         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | 2.03e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 736          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025266276 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0852       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 717          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "Model Accuracy: 78.38%\n",
      "Intervene: Cattle at risk of BRD.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Step 3: Create the Custom Environment for Bovine Respiratory Disease Prediction\n",
    "class BovineRespiratoryDiseaseEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(BovineRespiratoryDiseaseEnv, self).__init__()\n",
    "        \n",
    "        # Load the dataset containing cattle health metrics\n",
    "        self.data = data\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Action space: Decide on health intervention (e.g., increase observation, administer medication)\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = No intervention, 1 = Intervention\n",
    "        \n",
    "        # Observation space: Use the cattle health data features (e.g., temperature, heart rate)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(data.shape[1] - 1,), dtype=np.float32)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset the environment to the initial state\n",
    "        self.current_step = 0\n",
    "        return self.data.iloc[self.current_step, :-1].values\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Get current observation\n",
    "        observation = self.data.iloc[self.current_step, :-1].values\n",
    "        \n",
    "        # Calculate reward: higher rewards for correctly predicting intervention (preventing BRD)\n",
    "        reward = 0\n",
    "        if action == 1 and self.data.iloc[self.current_step]['clade'] == 1:  # Disease present, intervention made\n",
    "            reward = 10  # Positive reward for correct intervention\n",
    "        elif action == 0 and self.data.iloc[self.current_step]['clade'] == 0:  # No disease, no intervention\n",
    "            reward = 5  # Positive reward for no action when no disease present\n",
    "        else:\n",
    "            reward = -5  # Negative reward for incorrect action\n",
    "        \n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.data)\n",
    "        \n",
    "        return observation, reward, done, {}\n",
    "\n",
    "# Step 4: Load Your Dataset from a CSV File\n",
    "# Example: 'cattle_health_data.csv' should be replaced with your actual file path\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"global_meta.csv\")  # Correct method to read a CSV file\n",
    "\n",
    "# Step 5: Prepare Data for Training\n",
    "# Fill NaN values in the 'clade' column with 0\n",
    "data['clade'] = data['clade'].fillna(0).astype(int)\n",
    "\n",
    "# Normalize the data (optional but helpful for RL)\n",
    "# Make sure to normalize the feature columns (except for the target column 'clade')\n",
    "data_normalized = data.copy()\n",
    "\n",
    "# Select only numeric columns for normalization\n",
    "numeric_columns = data_normalized.select_dtypes(include=[np.number]).columns\n",
    "data_normalized[numeric_columns] = data_normalized[numeric_columns] / (data_normalized[numeric_columns].max() + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Ensure the environment receives only numeric data\n",
    "data_normalized = data_normalized[numeric_columns]\n",
    "\n",
    "# Check for NaN values in the data\n",
    "if data_normalized.isnull().sum().any():\n",
    "    print(\"NaN values detected! Replacing them.\")\n",
    "    data_normalized = data_normalized.fillna(0)\n",
    "\n",
    "# Step 6: Train the RL Model\n",
    "# Create the custom environment\n",
    "env = BovineRespiratoryDiseaseEnv(data_normalized)\n",
    "\n",
    "# Initialize the PPO model with a lower learning rate to avoid NaNs\n",
    "model = PPO('MlpPolicy', env, learning_rate=0.0001, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Step 7: Evaluate the Model and Calculate Accuracy\n",
    "# Initialize variables for tracking correct and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Test the trained agent\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    \n",
    "    # Compare predicted action to actual disease state to determine correctness\n",
    "    if (action == 1 and env.data.iloc[env.current_step - 1]['clade'] == 1) or \\\n",
    "       (action == 0 and env.data.iloc[env.current_step - 1]['clade'] == 0):\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "    \n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 8: Making Predictions with the Trained Model\n",
    "# Example: Make a prediction for the next cattle observation\n",
    "test_observation = np.array([0.6, 0.7, 0.8, 0.5])  # Replace with actual data\n",
    "\n",
    "# Ensure the test observation has the correct shape (should be 6 features, not 32)\n",
    "test_observation = np.array([0.6, 0.7, 0.8, 0.5, 0.3, 0.2])  # Replace with actual data\n",
    "\n",
    "# Reshape to match the expected input (1, 6) since it's a single sample\n",
    "test_observation = test_observation.reshape(1, -1)\n",
    "\n",
    "# Get the prediction\n",
    "action, _states = model.predict(test_observation)\n",
    "\n",
    "# Output action\n",
    "if action == 1:\n",
    "    print(\"Intervene: Cattle at risk of BRD.\")\n",
    "else:\n",
    "    print(\"No intervention needed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
