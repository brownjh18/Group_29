{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1231: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1716, 6039), Shape of y: (1716, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "C:\\Users\\HP DRAGON FLY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.6836 - val_accuracy: 0.9855 - val_loss: 0.6562 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.6461 - val_accuracy: 0.9855 - val_loss: 0.6213 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.6108 - val_accuracy: 0.9855 - val_loss: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.5775 - val_accuracy: 0.9855 - val_loss: 0.5578 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.5463 - val_accuracy: 0.9855 - val_loss: 0.5289 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.5170 - val_accuracy: 0.9855 - val_loss: 0.5019 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.4896 - val_accuracy: 0.9855 - val_loss: 0.4766 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.4638 - val_accuracy: 0.9855 - val_loss: 0.4529 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.4396 - val_accuracy: 0.9855 - val_loss: 0.4308 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.4170 - val_accuracy: 0.9855 - val_loss: 0.4100 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.3958 - val_accuracy: 0.9855 - val_loss: 0.3906 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.3759 - val_accuracy: 0.9855 - val_loss: 0.3725 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.3572 - val_accuracy: 0.9855 - val_loss: 0.3555 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9984 - loss: 0.3397 - val_accuracy: 0.9855 - val_loss: 0.3396 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.3233 - val_accuracy: 0.9855 - val_loss: 0.3247 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.3080 - val_accuracy: 0.9855 - val_loss: 0.3108 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2935 - val_accuracy: 0.9855 - val_loss: 0.2977 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2800 - val_accuracy: 0.9855 - val_loss: 0.2855 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2672 - val_accuracy: 0.9855 - val_loss: 0.2740 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2553 - val_accuracy: 0.9855 - val_loss: 0.2632 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2440 - val_accuracy: 0.9855 - val_loss: 0.2531 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.2334 - val_accuracy: 0.9855 - val_loss: 0.2436 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.2234 - val_accuracy: 0.9855 - val_loss: 0.2347 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.2140 - val_accuracy: 0.9855 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.2051 - val_accuracy: 0.9855 - val_loss: 0.2185 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.1967 - val_accuracy: 0.9855 - val_loss: 0.2110 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1888 - val_accuracy: 0.9855 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1813 - val_accuracy: 0.9855 - val_loss: 0.1974 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1743 - val_accuracy: 0.9855 - val_loss: 0.1912 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1676 - val_accuracy: 0.9855 - val_loss: 0.1853 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1612 - val_accuracy: 0.9855 - val_loss: 0.1798 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1552 - val_accuracy: 0.9855 - val_loss: 0.1746 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1495 - val_accuracy: 0.9855 - val_loss: 0.1696 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9984 - loss: 0.1441 - val_accuracy: 0.9855 - val_loss: 0.1649 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1390 - val_accuracy: 0.9855 - val_loss: 0.1605 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1341 - val_accuracy: 0.9855 - val_loss: 0.1563 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1295 - val_accuracy: 0.9855 - val_loss: 0.1523 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1251 - val_accuracy: 0.9855 - val_loss: 0.1486 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1209 - val_accuracy: 0.9855 - val_loss: 0.1450 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1169 - val_accuracy: 0.9855 - val_loss: 0.1416 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.1130 - val_accuracy: 0.9855 - val_loss: 0.1384 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1094 - val_accuracy: 0.9855 - val_loss: 0.1354 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1059 - val_accuracy: 0.9855 - val_loss: 0.1325 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.1026 - val_accuracy: 0.9855 - val_loss: 0.1297 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0994 - val_accuracy: 0.9855 - val_loss: 0.1271 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0964 - val_accuracy: 0.9855 - val_loss: 0.1246 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0935 - val_accuracy: 0.9855 - val_loss: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0907 - val_accuracy: 0.9855 - val_loss: 0.1199 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0881 - val_accuracy: 0.9855 - val_loss: 0.1178 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0855 - val_accuracy: 0.9855 - val_loss: 0.1157 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0831 - val_accuracy: 0.9855 - val_loss: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0807 - val_accuracy: 0.9855 - val_loss: 0.1119 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0785 - val_accuracy: 0.9855 - val_loss: 0.1102 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.0763 - val_accuracy: 0.9855 - val_loss: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0743 - val_accuracy: 0.9855 - val_loss: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0723 - val_accuracy: 0.9855 - val_loss: 0.1053 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0704 - val_accuracy: 0.9855 - val_loss: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.0685 - val_accuracy: 0.9855 - val_loss: 0.1024 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0668 - val_accuracy: 0.9855 - val_loss: 0.1011 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0651 - val_accuracy: 0.9855 - val_loss: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0634 - val_accuracy: 0.9855 - val_loss: 0.0986 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0618 - val_accuracy: 0.9855 - val_loss: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0603 - val_accuracy: 0.9855 - val_loss: 0.0963 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0589 - val_accuracy: 0.9855 - val_loss: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0574 - val_accuracy: 0.9855 - val_loss: 0.0942 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0561 - val_accuracy: 0.9855 - val_loss: 0.0933 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0548 - val_accuracy: 0.9855 - val_loss: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0535 - val_accuracy: 0.9855 - val_loss: 0.0914 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0523 - val_accuracy: 0.9855 - val_loss: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0511 - val_accuracy: 0.9855 - val_loss: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.0499 - val_accuracy: 0.9855 - val_loss: 0.0890 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0488 - val_accuracy: 0.9855 - val_loss: 0.0883 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0478 - val_accuracy: 0.9855 - val_loss: 0.0876 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0467 - val_accuracy: 0.9855 - val_loss: 0.0869 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0457 - val_accuracy: 0.9855 - val_loss: 0.0863 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0448 - val_accuracy: 0.9855 - val_loss: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0438 - val_accuracy: 0.9855 - val_loss: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0429 - val_accuracy: 0.9855 - val_loss: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0421 - val_accuracy: 0.9855 - val_loss: 0.0840 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0412 - val_accuracy: 0.9855 - val_loss: 0.0835 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0404 - val_accuracy: 0.9855 - val_loss: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0396 - val_accuracy: 0.9855 - val_loss: 0.0825 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.0388 - val_accuracy: 0.9855 - val_loss: 0.0821 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0381 - val_accuracy: 0.9855 - val_loss: 0.0816 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0373 - val_accuracy: 0.9855 - val_loss: 0.0813 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0366 - val_accuracy: 0.9855 - val_loss: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0360 - val_accuracy: 0.9855 - val_loss: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0353 - val_accuracy: 0.9855 - val_loss: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0347 - val_accuracy: 0.9855 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.0340 - val_accuracy: 0.9855 - val_loss: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0334 - val_accuracy: 0.9855 - val_loss: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0328 - val_accuracy: 0.9855 - val_loss: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0323 - val_accuracy: 0.9855 - val_loss: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0317 - val_accuracy: 0.9855 - val_loss: 0.0785 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0312 - val_accuracy: 0.9855 - val_loss: 0.0782 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0307 - val_accuracy: 0.9855 - val_loss: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9984 - loss: 0.0302 - val_accuracy: 0.9855 - val_loss: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0297 - val_accuracy: 0.9855 - val_loss: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0292 - val_accuracy: 0.9855 - val_loss: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0287 - val_accuracy: 0.9855 - val_loss: 0.0772 - learning_rate: 0.0010\n",
      "Epoch 1/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.0134 - val_accuracy: 0.9855 - val_loss: 0.0127 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0124 - val_accuracy: 0.9855 - val_loss: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0114 - val_accuracy: 0.9855 - val_loss: 0.0108 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0105 - val_accuracy: 0.9855 - val_loss: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0097 - val_accuracy: 0.9855 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0089 - val_accuracy: 0.9855 - val_loss: 0.0086 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0082 - val_accuracy: 0.9855 - val_loss: 0.0079 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0076 - val_accuracy: 0.9855 - val_loss: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 0.9855 - val_loss: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0065 - val_accuracy: 0.9855 - val_loss: 0.0063 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.9855 - val_loss: 0.0059 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9855 - val_loss: 0.0055 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9855 - val_loss: 0.0051 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9855 - val_loss: 0.0048 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9855 - val_loss: 0.0045 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.9855 - val_loss: 0.0042 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0038 - val_accuracy: 0.9855 - val_loss: 0.0040 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0036 - val_accuracy: 0.9855 - val_loss: 0.0037 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0033 - val_accuracy: 0.9855 - val_loss: 0.0035 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0031 - val_accuracy: 0.9855 - val_loss: 0.0034 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0029 - val_accuracy: 0.9855 - val_loss: 0.0032 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0027 - val_accuracy: 0.9855 - val_loss: 0.0030 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0026 - val_accuracy: 0.9855 - val_loss: 0.0029 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0024 - val_accuracy: 0.9855 - val_loss: 0.0027 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0023 - val_accuracy: 0.9855 - val_loss: 0.0026 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0022 - val_accuracy: 0.9855 - val_loss: 0.0025 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0020 - val_accuracy: 0.9855 - val_loss: 0.0024 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0019 - val_accuracy: 0.9855 - val_loss: 0.0023 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0018 - val_accuracy: 0.9855 - val_loss: 0.0022 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0017 - val_accuracy: 0.9855 - val_loss: 0.0021 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0017 - val_accuracy: 0.9855 - val_loss: 0.0021 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0016 - val_accuracy: 0.9855 - val_loss: 0.0020 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0015 - val_accuracy: 0.9855 - val_loss: 0.0019 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0014 - val_accuracy: 0.9855 - val_loss: 0.0019 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0014 - val_accuracy: 0.9855 - val_loss: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0013 - val_accuracy: 0.9855 - val_loss: 0.0018 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0012 - val_accuracy: 0.9855 - val_loss: 0.0017 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0012 - val_accuracy: 0.9855 - val_loss: 0.0017 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0011 - val_accuracy: 0.9855 - val_loss: 0.0016 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0011 - val_accuracy: 0.9855 - val_loss: 0.0016 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0010 - val_accuracy: 0.9855 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0010 - val_accuracy: 0.9855 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 9.6280e-04 - val_accuracy: 0.9855 - val_loss: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 9.2565e-04 - val_accuracy: 0.9855 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 8.9057e-04 - val_accuracy: 0.9855 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 8.5745e-04 - val_accuracy: 0.9855 - val_loss: 0.0014 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 8.2612e-04 - val_accuracy: 0.9855 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 7.9651e-04 - val_accuracy: 0.9855 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 7.6845e-04 - val_accuracy: 0.9855 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 7.4187e-04 - val_accuracy: 0.9855 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 7.1665e-04 - val_accuracy: 0.9855 - val_loss: 0.0013 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 6.9273e-04 - val_accuracy: 0.9855 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 6.7000e-04 - val_accuracy: 0.9855 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 6.4838e-04 - val_accuracy: 0.9855 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 6.2782e-04 - val_accuracy: 0.9855 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 6.0825e-04 - val_accuracy: 0.9855 - val_loss: 0.0012 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 5.8959e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.7396e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 5.6530e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.5677e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 5.4832e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.4003e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 5.3184e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 5.2376e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.1680e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 5.1283e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.0885e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.0487e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 5.0091e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.9740e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.9541e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.9336e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.9132e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8925e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 4.8742e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8638e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8530e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.8421e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8311e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.8214e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8157e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.8102e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.8042e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7982e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.1250e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7930e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 4.7900e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 4.7869e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7837e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.7804e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7778e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 4.7760e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7747e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.7725e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7708e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.7694e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 4.7685e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7675e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 4.7666e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 4.7657e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 4.7648e-04 - val_accuracy: 0.9855 - val_loss: 0.0011 - learning_rate: 1.9531e-06\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 7.7245e-04\n",
      "Student Model Accuracy: 99.71%\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Model Training Results Table:\n",
      "   Learning Rate  Training Rate  Student Model Accuracy (%)\n",
      "0          0.001            100                   99.709302\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'global_meta.csv'  # Update with actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Handle missing values by filling with the median for numerical columns and mode for categorical\n",
    "for col in data.select_dtypes(include=['number']).columns:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "# Assuming the last column is the target variable\n",
    "target_column = data.columns[-12]  # Replace with name if known\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Convert categorical columns to numerical using one-hot encoding\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Convert target variable to numerical if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# One-Hot Encode the target variable\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False) # Specify sparse=False\n",
    "y = onehot_encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Ensure dataset is not empty after preprocessing\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    X = X.fillna(X.median())  # Fill any remaining NaNs in numerical columns\n",
    "\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")  # Debugging step\n",
    "\n",
    "if X.shape[0] == 0:\n",
    "    raise ValueError(\"No valid data available after preprocessing.\")\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the teacher model (larger model)\n",
    "teacher = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(y.shape[1], activation='softmax')  # Output probabilities\n",
    "])\n",
    "teacher.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Changed loss/metrics\n",
    "\n",
    "# Define learning rate and training rate\n",
    "learning_rate = 0.001  # Learning rate\n",
    "training_rate = 100  # Number of epochs for training\n",
    "\n",
    "# Train the teacher model with EarlyStopping and ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "teacher.fit(X_train, y_train, epochs=training_rate, batch_size=32, validation_split=0.1, verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Define the student model (smaller model)\n",
    "student = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),  # Dropout layer to prevent overfitting\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(y.shape[1], activation='softmax')  # Output probabilities\n",
    "])\n",
    "\n",
    "# Define knowledge distillation loss function\n",
    "class DistillationLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=3.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Softmax probabilities for teacher and student\n",
    "        teacher_probs = tf.nn.softmax(y_true / self.temperature, axis=1)\n",
    "        student_probs = tf.nn.softmax(y_pred / self.temperature, axis=1)\n",
    "\n",
    "        # Calculate KL divergence\n",
    "        kl_divergence = tf.keras.losses.KLDivergence()(teacher_probs, student_probs)\n",
    "        return kl_divergence\n",
    "\n",
    "# Compile and train the student model\n",
    "student.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=DistillationLoss(), metrics=['accuracy'])  # Changed metric\n",
    "\n",
    "# Train with early stopping and learning rate reduction\n",
    "student.fit(X_train, y_train, epochs=training_rate, batch_size=32, validation_split=0.1, verbose=1, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the student model\n",
    "loss, accuracy = student.evaluate(X_test, y_test, verbose=1)\n",
    "accuracy_percentage = accuracy * 100\n",
    "print(f'Student Model Accuracy: {accuracy_percentage:.2f}%')\n",
    "\n",
    "# Make predictions - Decode One-Hot Encoded Predictions\n",
    "predictions = student.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode Labels\n",
    "original_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "print('Predictions:', original_labels[:10])\n",
    "\n",
    "# Step 1: Create the results table\n",
    "results = {\n",
    "    \"Learning Rate\": [learning_rate],\n",
    "    \"Training Rate\": [training_rate],\n",
    "    \"Student Model Accuracy (%)\": [accuracy_percentage],\n",
    "}\n",
    "\n",
    "results_table = pd.DataFrame(results)\n",
    "\n",
    "# Display the table of results\n",
    "print(\"\\nModel Training Results Table:\")\n",
    "print(results_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
